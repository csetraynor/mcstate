---
title: "Parallelisation of inference"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{sir_models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In the SIR model vignette we ran four separate MCMC chains in serial. For more computationally intensive models you can speed this up if you have many CPU cores available. If you have $m$ nodes available, each with $n$ cores, the most efficient way to run this step is to set `nthreads = n` on the filters, and run $m$ independent chains, one on each node setting `n_chains = 1`.

For threads to take effect, `openmp` must be enabled in the compilation step, which you can check by running:

```{r}
gen_sir <- dust::dust_example("sir")
gen_sir$public_methods$has_openmp()
```

These independent results can then be collected using `pmcmc_combine()`:

```{r pmcmc_serial, eval = FALSE}
pmcmc1 <- 
  pmcmc(
    mcmc_pars,
    filter,
    2000,
    save_state = TRUE,
    save_trajectories = FALSE,
    progress = TRUE,
    n_chains = 1
  )
pmcmc2 <- 
  pmcmc(
    mcmc_pars,
    filter,
    2000,
    save_state = TRUE,
    save_trajectories = FALSE,
    progress = TRUE,
    n_chains = 1
  )
pmcmc3 <- 
  pmcmc(
    mcmc_pars,
    filter,
    2000,
    save_state = TRUE,
    save_trajectories = FALSE,
    progress = TRUE,
    n_chains = 1
  )
pmcmc_distributed_run <- pmcmc_combine(pmcmc1, pmcmc2, pmcmc3)
```
